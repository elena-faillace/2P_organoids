{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the .csv files, get the df/f and save it in a .npy. \n",
    "\n",
    "Save the raw data. \n",
    "\n",
    "\n",
    "Save the deconvoluted spike trains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenafaillace/anaconda3/envs/organoids/lib/python3.10/site-packages/oasis/functions.py:13: UserWarning: Could not find cvxpy. Don't worry, you can still use OASIS, just not the slower interior point methods we compared to in the papers.\n",
      "  warn(\"Could not find cvxpy. Don't worry, you can still use OASIS, \" +\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "\n",
    "from tools import moving_average, get_dff, bin_traces, get_spike_trains\n",
    "from tools_figures import plot_dff_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordings to use\n",
    "recordings = {'1.young': ['20220627_14_41_37', '20220627_15_38_37', '20220627_15_56_22'],\n",
    "'2.medium': ['20220922_15_18_53', '20220922_16_18_38', '20221006_13_26_06'],\n",
    "'3.old': ['20220630_16_02_37'],\n",
    "'4.nawal': ['20220630_16_02_37', '20220630_16_15_02']}\n",
    "\n",
    "path_to_origin = '/Volumes/T7/organoids/for_paper/data/'\n",
    "\n",
    "window_size = 5\n",
    "bin_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning recording: 1.young - 20220627_14_41_37\n",
      "Cleaning recording: 1.young - 20220627_15_38_37\n",
      "Cleaning recording: 1.young - 20220627_15_56_22\n",
      "Cleaning recording: 2.medium - 20220922_15_18_53\n",
      "Cleaning recording: 2.medium - 20220922_16_18_38\n",
      "Cleaning recording: 2.medium - 20221006_13_26_06\n",
      "Cleaning recording: 3.old - 20220630_16_02_37\n",
      "Cleaning recording: 4.nawal - 20220630_16_02_37\n",
      "Could not load video: 4.nawal - 20220630_16_02_37\n",
      "Cleaning recording: 4.nawal - 20220630_16_15_02\n"
     ]
    }
   ],
   "source": [
    "# Go through each recording and save the dff\n",
    "for age in recordings.keys():\n",
    "    for recording in recordings[age]:\n",
    "        print('Cleaning recording: ' + age + ' - ' + recording)\n",
    "\n",
    "        # Load the video\n",
    "        try: \n",
    "            path_to_video = path_to_origin + age + '/' + recording + '/video.tif'\n",
    "            video = io.imread(path_to_video)\n",
    "        except:\n",
    "            print('Could not load video: ' + age + ' - ' + recording)\n",
    "            continue\n",
    "\n",
    "        # Get projection\n",
    "        projection = np.mean(video, axis=0)\n",
    "\n",
    "        # Load the recording's results\n",
    "        try:\n",
    "            path_to_recording = path_to_origin + age + '/' + recording + '/Results.csv'\n",
    "            df = pd.read_csv(path_to_recording)\n",
    "        except:\n",
    "            print('Could not load csv: ' + age + ' - ' + recording)\n",
    "            continue\n",
    "\n",
    "        # Get the ROIs df\n",
    "        rois_names = [col for col in df.columns if col.startswith('Mean')]\n",
    "        traces = df[rois_names].values # time_points x rois \n",
    "\n",
    "        # Bin the traces\n",
    "        b_traces = bin_traces(traces, bin_size)\n",
    "\n",
    "        # Apply moving average\n",
    "        smooth_traces = moving_average(b_traces, window_size)\n",
    "        # Remove edges to avoid artifacts\n",
    "        smooth_traces = smooth_traces[window_size:-window_size,:]\n",
    "\n",
    "        # Get df/f\n",
    "        dff = get_dff(smooth_traces)\n",
    "        # Plot it\n",
    "        plot_dff_single(age, recording, max_cells=20)\n",
    "\n",
    "        # Get the spike trains\n",
    "        # TODO: Remove as it is useless\n",
    "        spike_trains = get_spike_trains(dff)\n",
    "\n",
    "        # Save the dff\n",
    "        path_to_save = path_to_origin + age + '/' + recording + '/dff.npy'\n",
    "        np.save(path_to_save, dff)\n",
    "        # Save the raw traces\n",
    "        path_to_save = path_to_origin + age + '/' + recording + '/raw_traces.npy'\n",
    "        np.save(path_to_save, traces)\n",
    "        # Save the spike trains\n",
    "        path_to_save = path_to_origin + age + '/' + recording + '/spike_trains.npy'\n",
    "        np.save(path_to_save, spike_trains) \n",
    "        # Save the projection\n",
    "        path_to_save = path_to_origin + age + '/' + recording + '/projection.npy'\n",
    "        np.save(path_to_save, projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
